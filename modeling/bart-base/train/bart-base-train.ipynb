{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 檢查GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jan  7 12:12:50 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.141.03   Driver Version: 470.141.03   CUDA Version: 11.4     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA TITAN RTX    Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 39%   53C    P0    67W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA TITAN RTX    Off  | 00000000:02:00.0 Off |                  N/A |\n",
      "| 36%   41C    P0    58W / 280W |      0MiB / 24220MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基本 Import 環境安裝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-07 12:12:51.514574: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-01-07 12:12:51.627972: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-01-07 12:12:52.116969: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-07 12:12:52.117128: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvrtc.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-07 12:12:52.117136: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BartTokenizer, BartForConditionalGeneration\n",
    "import torch\n",
    "import json\n",
    "import os, sys"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入資料集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(item):\n",
    "    path = '/user_data/MedQA_DG/data/data_clean/questions/US/{}.json'.format(item)\n",
    "    with open(path) as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train = read_data('train')\n",
    "test = read_data('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10178, 1273)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train), len(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data format 資料格式\n",
    "\n",
    "- version : <String> 問題內容\n",
    "- answer : <String> 答案內容\n",
    "- options : <Arrays> 選項內容\n",
    "  - id : <String> 有 A B C D E 五種不同的選項，其中一個是正確答案\n",
    "  - text : <string> 選項內容\n",
    "- answer_idx : <string> 答案的ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'A 23-year-old pregnant woman at 22 weeks gestation presents with burning upon urination. She states it started 1 day ago and has been worsening despite drinking more water and taking cranberry extract. She otherwise feels well and is followed by a doctor for her pregnancy. Her temperature is 97.7°F (36.5°C), blood pressure is 122/77 mmHg, pulse is 80/min, respirations are 19/min, and oxygen saturation is 98% on room air. Physical exam is notable for an absence of costovertebral angle tenderness and a gravid uterus. Which of the following is the best treatment for this patient?',\n",
       " 'answer': 'Nitrofurantoin',\n",
       " 'options': {'A': 'Ampicillin',\n",
       "  'B': 'Ceftriaxone',\n",
       "  'C': 'Ciprofloxacin',\n",
       "  'D': 'Doxycycline',\n",
       "  'E': 'Nitrofurantoin'},\n",
       " 'meta_info': 'step2&3',\n",
       " 'answer_idx': 'E'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9160, 1018)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, valid = train_test_split(train, random_state=777, train_size=0.9)\n",
    "len(train), len(valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = BartTokenizer.from_pretrained('facebook/bart-base')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加入 Special Token 來區隔 distractor | EOD = End of Distractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "eod_toks = tokenizer.add_tokens(['[EOD]'], special_tokens=True) ##This line is updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def processData(data):\n",
    "    questions = []\n",
    "    labels = []\n",
    "    answers = []\n",
    "    for d in data:\n",
    "        question = d['question']\n",
    "        options = d['options']\n",
    "        answer_idx = d['answer_idx']\n",
    "\n",
    "        answer = d['answer']\n",
    "\n",
    "        distractors = []\n",
    "        for value in options.values():\n",
    "            if value != answer:\n",
    "                distractors.append(value)\n",
    "\n",
    "        labels.append('[EOD]'.join(distractors))\n",
    "        answers.append(answer)\n",
    "        questions.append(question)\n",
    "    \n",
    "    return questions, answers, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_question, train_answer, train_label = processData(train)\n",
    "valid_question, valid_answer, valid_label = processData(valid)\n",
    "test_question, test_answer, test_label = processData(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ethics committee consultation[EOD]Cerebral angiography[EOD]Court order for further management[EOD]Repeat CT scan of the head'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "問題 :  Four days after being hospitalized, intubated, and mechanically ventilated, a 30-year-old man has no cough response during tracheal suctioning. He was involved in a motor vehicle collision and was obtunded on arrival in the emergency department. The ventilator is at a FiO2 of 100%, tidal volume is 920 mL, and positive end-expiratory pressure is 5 cm H2O. He is currently receiving vasopressors. His vital signs are within normal limits. The pupils are dilated and nonreactive to light. Corneal, gag, and oculovestibular reflexes are absent. There is no facial or upper extremity response to painful stimuli; the lower extremities show a triple flexion response to painful stimuli. Serum concentrations of electrolytes, urea, creatinine, and glucose are within the reference range. Arterial blood gas shows:\n",
      "pH 7.45\n",
      "pCO2 41 mm Hg\n",
      "pO2 99 mm Hg\n",
      "O2 saturation 99%\n",
      "Two days ago, a CT scan of the head showed a left intracerebral hemorrhage with mass effect. The apnea test is positive. There are no known family members, advanced directives, or individuals with power of attorney. Which of the following is the most appropriate next step in management?\" \n",
      "\n",
      "答案 :  Remove the ventilator \n",
      "\n",
      "選項 :  Ethics committee consultation[EOD]Cerebral angiography[EOD]Court order for further management[EOD]Repeat CT scan of the head \n",
      "\n",
      "***************\n",
      "\n",
      "問題 :  A 23-year-old woman comes to the physician because of vaginal discharge for 4 days. Her last menstrual period was 3 weeks ago. Twelve months ago, she was diagnosed with trichomoniasis, for which she and her partner were treated with a course of an antimicrobial. She is sexually active with one male partner, and they use condoms inconsistently. Her only medication is a combined oral contraceptive that she has been taking for the past 4 years. A Gram stain of her vaginal fluid is shown. Which of the following is the most likely causal organism? \n",
      "\n",
      "答案 :  Neisseria gonorrhoeae \n",
      "\n",
      "選項 :  Gardnerella vaginalis[EOD]Haemophilus ducreyi[EOD]Klebsiella granulomatis[EOD]Treponema pallidum \n",
      "\n",
      "***************\n"
     ]
    }
   ],
   "source": [
    "for idx in range(2):\n",
    "    print(\"\\n問題 : \",train_question[idx],'\\n')\n",
    "    print(\"答案 : \",train_answer[idx],'\\n')\n",
    "    print(\"選項 : \",train_label[idx],'\\n')\n",
    "    print('*'*15)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_question, train_answer, truncation=True, padding=True)\n",
    "valid_encodings = tokenizer(valid_question, valid_answer, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_question, test_answer, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_encodings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def add_labels(encodings, distractors):\n",
    "    \n",
    "    distractors_encodings = tokenizer(distractors, padding=True)\n",
    "    labels = []\n",
    "    for i in range(len(distractors_encodings.input_ids)):\n",
    "        labels.append(distractors_encodings.input_ids[i])\n",
    "    \n",
    "    encodings[\"labels\"] = labels\n",
    "    return encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = add_labels(train_encodings, train_label)\n",
    "valid_encodings = add_labels(valid_encodings, valid_label)\n",
    "test_encodings = add_labels(test_encodings, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ethics committee consultation[EOD]Cerebral angiography[EOD]Court order for further management[EOD]Repeat CT scan of the head'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### token_id = 50265  --> token = EOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 42301, 2857, 1540, 9434, 50265, 347, 2816, 44283, 5667, 118, 10486, 50265, 37349, 645, 13, 617, 1052, 50265, 45764, 12464, 14194, 9, 5, 471, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(train_encodings.labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>Ethics committee consultation [EOD] Cerebral angiography [EOD] Court order for further management [EOD] Repeat CT scan of the head</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(train_encodings.labels[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data ot Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class MedQADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "train_dataset = MedQADataset(train_encodings)\n",
    "valid_dataset = MedQADataset(valid_encodings)\n",
    "test_dataset = MedQADataset(test_encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9160, 1018, 1273)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(valid_dataset), len(test_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50266, 768)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BartForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "import torch\n",
    "\n",
    "model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-base\")\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir = \"./model\",\n",
    "    save_strategy = \"epoch\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"P@1\",\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    eval_accumulation_steps = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    \n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    \n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # store all article\n",
    "    predicted = []\n",
    "    true_label = []\n",
    "    \n",
    "    for k in range(len(decoded_labels)):\n",
    "        pred = decoded_preds[k]\n",
    "        label = decoded_labels[k]\n",
    "\n",
    "        pred_list = pred.split(', ')\n",
    "        label_list = label.split(', ')\n",
    "        \n",
    "        pred_list[0] = pred_list[0].split(' ')[-1]\n",
    "        label_list[0] = label_list[0].split(' ')[-1]\n",
    "\n",
    "        predicted.append(pred_list)\n",
    "        true_label.append(label_list)\n",
    "\n",
    "    # evaluation metrics\n",
    "    p1 = 0\n",
    "    p3 = 0\n",
    "    r3 = 0\n",
    "    f3 = 0\n",
    "    for idx in range(len(true_label)):\n",
    "        distractors = predicted[idx]\n",
    "        labels = true_label[idx]\n",
    "\n",
    "        act_set = set(labels)\n",
    "        pred1_set = set(distractors[:1])\n",
    "        pred3_set = set(distractors[:3])\n",
    "\n",
    "        p_1 = len(act_set & pred1_set) / float(1)\n",
    "        p_3 = len(act_set & pred3_set) / float(3)\n",
    "        r_3 = len(act_set & pred3_set) / float(len(act_set))\n",
    "\n",
    "        if p_3 == 0 and r_3 == 0:\n",
    "            f1_3 = 0\n",
    "        else:\n",
    "            f1_3 = 2 * (p_3 * r_3 / (p_3 + r_3))\n",
    "\n",
    "        p1+=p_1\n",
    "        p3+=p_3\n",
    "        r3+=r_3\n",
    "        f3+=f1_3\n",
    "\n",
    "    avg_p1 = p1 / len(true_label)\n",
    "    avg_p3 = p3 / len(true_label)\n",
    "    avg_r3 = r3 / len(true_label)\n",
    "    avg_f3 = f3 / len(true_label)\n",
    "\n",
    "    result = {'P@1': avg_p1,\n",
    "              'P@3': avg_p3,\n",
    "              'R@3': avg_r3,\n",
    "              'F1@3': avg_f3}\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Seq2SeqTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 9160\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 22900\n",
      "Automatic Weights & Biases logging enabled, to disable set os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhankystyle\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/user_data/MedQA_DG/model/bart-base/train/wandb/run-20230107_121324-2j8fltyc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hankystyle/huggingface/runs/2j8fltyc\" target=\"_blank\">./model</a></strong> to <a href=\"https://wandb.ai/hankystyle/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='22900' max='22900' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [22900/22900 1:22:17, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>P@1</th>\n",
       "      <th>P@3</th>\n",
       "      <th>R@3</th>\n",
       "      <th>F1@3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.531200</td>\n",
       "      <td>0.416468</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.016372</td>\n",
       "      <td>0.023625</td>\n",
       "      <td>0.015591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.459800</td>\n",
       "      <td>0.387879</td>\n",
       "      <td>0.024558</td>\n",
       "      <td>0.013752</td>\n",
       "      <td>0.017140</td>\n",
       "      <td>0.012280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.406000</td>\n",
       "      <td>0.374630</td>\n",
       "      <td>0.023576</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>0.014685</td>\n",
       "      <td>0.011014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.380800</td>\n",
       "      <td>0.365723</td>\n",
       "      <td>0.030452</td>\n",
       "      <td>0.016045</td>\n",
       "      <td>0.022029</td>\n",
       "      <td>0.014976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.356800</td>\n",
       "      <td>0.361149</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.014735</td>\n",
       "      <td>0.020438</td>\n",
       "      <td>0.013765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>0.357996</td>\n",
       "      <td>0.031434</td>\n",
       "      <td>0.015717</td>\n",
       "      <td>0.023689</td>\n",
       "      <td>0.015391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>0.355934</td>\n",
       "      <td>0.029470</td>\n",
       "      <td>0.015062</td>\n",
       "      <td>0.020742</td>\n",
       "      <td>0.014070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.306300</td>\n",
       "      <td>0.356089</td>\n",
       "      <td>0.026523</td>\n",
       "      <td>0.014080</td>\n",
       "      <td>0.017632</td>\n",
       "      <td>0.012488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.291900</td>\n",
       "      <td>0.355944</td>\n",
       "      <td>0.034381</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>0.024835</td>\n",
       "      <td>0.016253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>0.356806</td>\n",
       "      <td>0.038310</td>\n",
       "      <td>0.018009</td>\n",
       "      <td>0.028765</td>\n",
       "      <td>0.018218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-2290\n",
      "Configuration saved in ./model/checkpoint-2290/config.json\n",
      "Model weights saved in ./model/checkpoint-2290/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-2290/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-2290/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-2290/added_tokens.json\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-4580\n",
      "Configuration saved in ./model/checkpoint-4580/config.json\n",
      "Model weights saved in ./model/checkpoint-4580/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-4580/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-4580/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-4580/added_tokens.json\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-6870\n",
      "Configuration saved in ./model/checkpoint-6870/config.json\n",
      "Model weights saved in ./model/checkpoint-6870/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-6870/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-6870/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-6870/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-4580] due to args.save_total_limit\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-9160\n",
      "Configuration saved in ./model/checkpoint-9160/config.json\n",
      "Model weights saved in ./model/checkpoint-9160/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-9160/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-9160/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-9160/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-6870] due to args.save_total_limit\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-11450\n",
      "Configuration saved in ./model/checkpoint-11450/config.json\n",
      "Model weights saved in ./model/checkpoint-11450/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-11450/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-11450/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-11450/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-9160] due to args.save_total_limit\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-13740\n",
      "Configuration saved in ./model/checkpoint-13740/config.json\n",
      "Model weights saved in ./model/checkpoint-13740/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-13740/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-13740/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-13740/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-11450] due to args.save_total_limit\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-16030\n",
      "Configuration saved in ./model/checkpoint-16030/config.json\n",
      "Model weights saved in ./model/checkpoint-16030/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-16030/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-16030/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-16030/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-13740] due to args.save_total_limit\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-18320\n",
      "Configuration saved in ./model/checkpoint-18320/config.json\n",
      "Model weights saved in ./model/checkpoint-18320/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-18320/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-18320/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-18320/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-16030] due to args.save_total_limit\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-20610\n",
      "Configuration saved in ./model/checkpoint-20610/config.json\n",
      "Model weights saved in ./model/checkpoint-20610/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-20610/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-20610/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-20610/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-2290] due to args.save_total_limit\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "Saving model checkpoint to ./model/checkpoint-22900\n",
      "Configuration saved in ./model/checkpoint-22900/config.json\n",
      "Model weights saved in ./model/checkpoint-22900/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/checkpoint-22900/tokenizer_config.json\n",
      "Special tokens file saved in ./model/checkpoint-22900/special_tokens_map.json\n",
      "added tokens file saved in ./model/checkpoint-22900/added_tokens.json\n",
      "Deleting older checkpoint [model/checkpoint-18320] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./model/checkpoint-22900 (score: 0.03831041257367387).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=22900, training_loss=0.3992818330989654, metrics={'train_runtime': 4941.4459, 'train_samples_per_second': 18.537, 'train_steps_per_second': 4.634, 'total_flos': 5.7706315849728e+16, 'train_loss': 0.3992818330989654, 'epoch': 10.0})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n",
      "/user_data/.local/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='829' max='255' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [255/255 09:28]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3568064868450165,\n",
       " 'eval_P@1': 0.03831041257367387,\n",
       " 'eval_P@3': 0.018009168303863784,\n",
       " 'eval_R@3': 0.02876459283888712,\n",
       " 'eval_F1@3': 0.018217893217893213,\n",
       " 'eval_runtime': 65.8772,\n",
       " 'eval_samples_per_second': 15.453,\n",
       " 'eval_steps_per_second': 3.871,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./model/bart-base-finetuned-pubmed-text2text-sentence-medqa\n",
      "Configuration saved in ./model/bart-base-finetuned-pubmed-text2text-sentence-medqa/config.json\n",
      "Model weights saved in ./model/bart-base-finetuned-pubmed-text2text-sentence-medqa/pytorch_model.bin\n",
      "tokenizer config file saved in ./model/bart-base-finetuned-pubmed-text2text-sentence-medqa/tokenizer_config.json\n",
      "Special tokens file saved in ./model/bart-base-finetuned-pubmed-text2text-sentence-medqa/special_tokens_map.json\n",
      "added tokens file saved in ./model/bart-base-finetuned-pubmed-text2text-sentence-medqa/added_tokens.json\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model('./model/bart-base-finetuned-pubmed-text2text-sentence-medqa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1018\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3568064868450165,\n",
       " 'eval_P@1': 0.03831041257367387,\n",
       " 'eval_P@3': 0.018009168303863784,\n",
       " 'eval_R@3': 0.02876459283888712,\n",
       " 'eval_F1@3': 0.018217893217893213,\n",
       " 'eval_runtime': 65.7013,\n",
       " 'eval_samples_per_second': 15.494,\n",
       " 'eval_steps_per_second': 3.881}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(valid_dataset)\n",
    "print('valid: ')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 1273\n",
      "  Batch size = 4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.470745712518692,\n",
       " 'eval_P@1': 0.03220738413197172,\n",
       " 'eval_P@3': 0.013877978528410582,\n",
       " 'eval_R@3': 0.02586512073943339,\n",
       " 'eval_F1@3': 0.01564749730499927,\n",
       " 'eval_runtime': 92.3145,\n",
       " 'eval_samples_per_second': 13.79,\n",
       " 'eval_steps_per_second': 3.456}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions, labels, metrics = trainer.predict(test_dataset)\n",
    "print('test: ')\n",
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_tokens = tokenizer.batch_decode(predictions,skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "predictions_tokens = tokenizer.batch_decode(predictions,skip_special_tokens = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open('pred.json','w') as f:\n",
    "    json.dump(predictions_tokens,f,skipkeys=['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open('pred.json','w') as f:\n",
    "    json.dump(predictions_tokens,f,skipkeys=['<pad>','</s>','<s>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "with open('test.json','w') as f:\n",
    "    json.dump(test_label,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
